{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69520fc7",
   "metadata": {},
   "source": [
    "# Simulation Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3379d6",
   "metadata": {},
   "source": [
    "1. Simulate the true event time vectors for both target and source, denoted as $\\mathbf{Y}_s\\mathbf{Y}_t$: \n",
    "\n",
    "*The source model is*\n",
    "\n",
    "$$\\log y_s = \\mathbf{x}_s^T\\boldsymbol{\\omega}_s+\\sigma_s\\epsilon_s,\\mathbf{x}_s\\sim\\mathcal{N}(\\mathbf{0},I),\\epsilon_s\\sim\\mathcal{N}(0, 1)$$ \n",
    "\n",
    "*and the target model:*\n",
    "\n",
    "$$\\log y_t = \\mathbf{x}_t^T\\boldsymbol{\\beta}+\\sigma_t\\epsilon_t,\\mathbf{x}_t\\sim\\mathcal{N}(\\mathbf{0},I),\\epsilon_t\\sim\\mathcal{N}(0, 1).$$\n",
    "\n",
    "Generate 10000 $y_s$ and 1000 $y_t$ using $\\boldsymbol{\\beta},\\boldsymbol{\\omega}\\in R^{500}$ and $\\mathbf{x}_t,\\mathbf{x}_s\\in R^{500}$. Note that for each pair $(\\omega_j,\\beta_j),j=1,\\cdots,500$, we have\n",
    "\n",
    "$$(\\omega_j,\\beta_j)\\sim^{i.i.d}\\mathcal{N}\\left(0,\\frac{1}{p}\\left(\\begin{matrix}\\alpha_s^{2}&\\rho\\alpha_s\\alpha_t\\\\\\rho\\alpha_s\\alpha_t&\\alpha_t^{2}\\end{matrix}\\right)\\right)$$. Repeat the process for 10 times, then set $\\beta_j$ equalling to the average of the 10 $\\beta_js$\n",
    "\n",
    "*We consider right censoring,*\n",
    "- Assume 20% of source populations are censored and 40% of target population are censored\n",
    "- We observe $(Y_{s},\\delta_{s})\\ (Y_{t},\\delta_{t})$, where $\\delta_i,\\ i\\in\\{s,t\\}$ is the binary censoring indicator, with 1 denoting event and 0 denoting censoring.\n",
    "\n",
    "2. Split the target data into testing and training part in a ratio of 1:9, named as $X_{target\\ training}$\n",
    " and $X_{target\\ testing}$\n",
    "3. Apply the methods  (we use CoxKL in this setting; can also consider using Tian Gu's Angle TL,RF,Commute - BUT binary outcomes only) to obtain $\\widehat{\\boldsymbol{\\omega}}_1,\\cdots,\\widehat{\\boldsymbol{\\omega}}_{10}$ to estimate $\\widehat{\\beta}$, and then obtain $X_{target\\ training}\\widehat{\\beta}$ \n",
    "4. We then obtain $X_{target\\ training}\\boldsymbol{\\omega}_1,\\cdots,X_{target\\ training}\\boldsymbol{\\omega}_{10}$\n",
    "5. Regress $Y_{target\\ testing}$ on $X_{target\\ training}\\boldsymbol{\\omega}_1,\\cdots,X_{target\\ training}\\boldsymbol{\\omega}_{10},X_{target\\ training}\\widehat{\\beta}$ with $L_2$ penalty.\n",
    "\n",
    "$$\\gamma=\\arg\\min \\prod_{i=1}^nf(y_i)+\\lambda\\lVert\\gamma\\lVert_2^2$$\n",
    "\n",
    "where $$f(y_i)$$ is the log-normal density and $$\\log Y_{target\\ testing}=X_{target\\ training}\\boldsymbol{\\omega}_1\\gamma_1+\\cdots+X_{target\\ training}\\boldsymbol{\\omega}_{10}\\gamma_{10}+ X_{target\\ training}\\widehat{\\beta}\\gamma_{11}+\\boldsymbol\\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec19864",
   "metadata": {},
   "source": [
    "# Simulation Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bc89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)  # Set a random seed for reproducibility\n",
    "\n",
    "# Set the dimensions and number of repetitions\n",
    "n_reps = 10\n",
    "n_variables = 500\n",
    "n_source = 10000\n",
    "n_target = 1000\n",
    "\n",
    "# Set the parameters\n",
    "alpha_s = 1.5\n",
    "alpha_t = 2.0\n",
    "rho = 0.5\n",
    "p = n_variables\n",
    "\n",
    "# Set the censoring proportions\n",
    "censor_prop_s = 0.2\n",
    "censor_prop_t = 0.4\n",
    "\n",
    "# Initialize the beta_j values\n",
    "beta_j_values = np.zeros(n_variables)\n",
    "\n",
    "# Loop for repetitions\n",
    "omega = {}\n",
    "beta = {}\n",
    "X_s ={}\n",
    "X_t = {}\n",
    "for rep in range(n_reps):\n",
    "    # Generate the omega_j and beta_j values\n",
    "    params = np.random.multivariate_normal(\n",
    "        mean=np.zeros(2), cov=(1/p)*np.array([[alpha_s**2, rho*alpha_s*alpha_t],\n",
    "                                              [rho*alpha_s*alpha_t, alpha_t**2]]), size=n_variables)\n",
    "    beta[rep] = params[:,1]\n",
    "    omega[rep] = params[:,0]\n",
    "    # Generate X_s and X_t\n",
    "    X_s[rep] = np.random.normal(0, 1, size=(n_source,n_variables))\n",
    "    X_t[rep] = np.random.normal(0, 1, size=(n_target,n_variables ))\n",
    "\n",
    "beta = sum(beta.values())/len(beta)\n",
    "\n",
    "Y_s = {}\n",
    "Y_t = {}\n",
    "# Generate true event times for source and target\n",
    "for rep in range(n_reps):\n",
    "    Y_s[rep] = np.exp(np.dot(X_s[rep], beta) + alpha_s * np.random.normal(0, 1, size=(n_source)))\n",
    "    Y_t[rep] = np.exp(np.dot(X_t[rep], beta) + alpha_t * np.random.normal(0, 1, size=(n_target)))\n",
    "\n",
    "# Generate censoring indicators\n",
    "delta_s = {}\n",
    "delta_t = {}\n",
    "for rep in range(n_reps):\n",
    "    delta_s[rep] = np.random.binomial(1, 1 - censor_prop_s, size=(n_source))\n",
    "    delta_t[rep] = np.random.binomial(1, 1 - censor_prop_t, size=(n_target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae6eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_s: (10000,)\n",
      "Shape of Y_t: (1000,)\n",
      "Shape of delta_s: (10000,)\n",
      "Shape of delta_t: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the generated data\n",
    "print(\"Shape of Y_s:\", Y_s[0].shape)\n",
    "print(\"Shape of Y_t:\", Y_t[0].shape)\n",
    "print(\"Shape of delta_s:\", delta_s[0].shape)\n",
    "print(\"Shape of delta_t:\", delta_t[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8dcbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 900\n",
      "Testing data size: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example target data\n",
    "target_data = X_t[0]\n",
    "# Split the target data into training and testing sets\n",
    "train_data, test_data = train_test_split(target_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print the sizes of training and testing data\n",
    "print(\"Training data size:\", len(train_data))\n",
    "print(\"Testing data size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011ce301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21625692, -0.48105502,  0.71760162, ...,  0.53071139,\n",
       "        -0.28713517,  0.06196288],\n",
       "       [-0.19992898, -1.50499575, -0.31832847, ..., -0.56347882,\n",
       "        -2.05242369, -0.23544354],\n",
       "       [-0.10844845,  0.19106596,  0.69127869, ..., -0.74100437,\n",
       "        -0.26464787,  1.46974139],\n",
       "       ...,\n",
       "       [-0.25055417, -0.70811843, -0.90249597, ..., -0.12292629,\n",
       "         0.38296632,  0.97308045],\n",
       "       [-0.72488855, -1.95825164, -0.24491906, ...,  0.80668976,\n",
       "         0.33001366,  1.74317542],\n",
       "       [ 0.58276882, -0.79983819,  0.85262011, ..., -0.20649288,\n",
       "         0.26881924,  0.30352573]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff3a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
